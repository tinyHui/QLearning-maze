{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mazes generator test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bin.maze import Maze\n",
    "\n",
    "m = Maze(size=(59, 99), verbose=False)\n",
    "m.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC+CAIAAAAEFiLKAAACoElEQVR4nO3dQYrjMBBA0U4z979y\nZtsrBb4oJIf3tiaOEz5aiEL++QEAAAAAgE9eH66/1xeXl8e8XqvHfr+nnuqJ3zv32d/FNViQDpF0\niKRDJB0i6RBJh0g6RNIh+re+vN4vXu827ji1M3vqznO/d45Vh0g6RNIhkg6RdIikQyQdIukQSYfo\nw27yjifukN75zDtPNfeLrDpE0iGSDpF0iKRDJB0i6RBJh0g6RIO7yXNTwHPm5otPzXHPfa9Vh0g6\nRNIhkg6RdIikQyQdIukQSYfokbPJTzxhY+fOp87QcG4yI6RDJB0i6RBJh0g6RNIhkg6RdIgunU2+\n88SJJ+5iz7050KpDJB0i6RBJh0g6RNIhkg6RdIikQ7S1m3xqz/fUOcKn5ovvZNUhkg6RdIikQyQd\nIukQSYdIOkTSIfqwxblzJu+pz57yxGfeYdUhkg6RdIikQyQdIukQSYdIOkTSIRo86WLO3IzwE89N\nPrVrb9Uhkg6RdIikQyQdIukQSYdIOkTSIbr03OTvu/P3seoQSYdIOkTSIZIOkXSIpEMkHSLpEG2d\ndLH1xYdmhHecmhE+xWwyI6RDJB0i6RBJh0g6RNIhkg6RdIi2ZpPvnBH+vvOL73xmqw6RdIikQyQd\nIukQSYdIOkTSIZIO0bHZ5B1PnPM9xbnJXEc6RNIhkg6RdIikQyQdIukQSYdocDb5zhnhO99od+d/\ntWbVIZIOkXSIpEMkHSLpEEmHSDpE0iEafAvfDvPFf935b1h1iKRDJB0i6RBJh0g6RNIhkg6RdIgu\n3U1emzvpYmcK+NRnT739z6pDJB0i6RBJh0g6RNIhkg6RdIikQ/TI3eQdd875rn3Yaz50DoZVh0g6\nRNIhkg6RdIikQyQdIukQSQcAAAAAABjzH5/VnHEuXhtNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bin.maze import Maze\n",
    "m = Maze(size=(19, 19), verbose=False)\n",
    "m.generate()\n",
    "m.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC+CAIAAAAEFiLKAAACtUlEQVR4nO3dUYrjMBQAwcky979y\n9gYytHjIGqp+jRMnNPoQD/nnBwAAAAAAnnwern/XF5eXx3w+q8f+fqee6sbvnbv33+IaLEiHSDpE\n0iGSDpF0iKRDJB0i6RD9ri+v90fXu407Tu3Mnvrkud87x6pDJB0i6RBJh0g6RNIhkg6RdIikQ/Sw\nm7zjxh3Sdz7zzlPN/SKrDpF0iKRDJB0i6RBJh0g6RNIhkg7R4G7y3BTwnLn54lNz3HPfa9Uhkg6R\ndIikQyQdIukQSYdIOkTSIbpyNvnGEzZ2PvnUGRrOTWaEdIikQyQdIukQSYdIOkTSIZIO0Utnk995\n4sSNu9hzbw606hBJh0g6RNIhkg6RdIikQyQdIukQbe0mT275Tu2Bnrr3xnM/1qw6RNIhkg6RdIik\nQyQdIukQSYdIOkQPW5w7Z/Lu3bt6qnduzJ46v/gUqw6RdIikQyQdIukQSYdIOkTSIZIO0eBJF3Pm\nZoRvPDf51I6/VYdIOkTSIZIOkXSIpEMkHSLpEEmH6KXnJv+9T/57rDpE0iGSDpF0iKRDJB0i6RBJ\nh0g6RFsnXWx98cZJF3vumxE+xWwyI6RDJB0i6RBJh0g6RNIhkg6RdIi2ZpMnZ4T7vU9nLt83ffzO\nZ7bqEEmHSDpE0iGSDpF0iKRDJB0i6RAdm03ecW6u+ZQ3zlNbdYikQyQdIukQSYdIOkTSIZIOkXSI\nBmeTd3Yq95x5K93evYuLZpP5W6RDJB0i6RBJh0g6RNIhkg6RdIgG38K3450z0afs/RlT/6RVh0g6\nRNIhkg6RdIikQyQdIukQSYfopbvJa3NvtNuZAt67N9+6Nde8819ZdYikQyQdIukQSYdIOkTSIZIO\nkXSIrtxN3nHj1PPDPvWhYzCsOkTSIZIOkXSIpEMkHSLpEEmHSDoAAAAAAMCY/2jil3P/MxLtAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bin.walker import Walker\n",
    "from random import choice, randint\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "GAMMA = 0.8\n",
    "REWARD = 15\n",
    "\n",
    "class QLearning:\n",
    "    def __init__(self, walker, states, actions, episode=50):\n",
    "        self.qmatrix = np.zeros((len(states), len(actions)))\n",
    "        self.walker = walker\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.episode = episode\n",
    "    \n",
    "    def train(self):\n",
    "        for _ in range(self.episode):\n",
    "            while not self.walker.is_end():              \n",
    "                available_actions = self.walker.get_available_moves()\n",
    "\n",
    "                for action in available_actions:\n",
    "                    reward = 0\n",
    "                    if self.walker.target_is_end(action):\n",
    "                        reward = REWARD\n",
    "                        \n",
    "                    ############ TODO ##############\n",
    "                    next_action_award = []\n",
    "                    self.walker.assume_move(action)\n",
    "                    further_available_actions = self.walker.get_available_moves()\n",
    "                    for further_action in further_available_actions:\n",
    "                        cell_indx = self.states.index(self.walker.get_current_cell())\n",
    "                        action_indx = self.actions.index(further_action)\n",
    "                        next_action_award.append(self.qmatrix[cell_indx, action_indx])\n",
    "                    \n",
    "                    self.walker.undo_move()\n",
    "                    #############################$$\n",
    "                    \n",
    "                    cell_indx = self.states.index(self.walker.get_current_cell())\n",
    "                    action_indx = self.actions.index(action)\n",
    "                    self.qmatrix[cell_indx, action_indx] = reward + GAMMA * max(next_action_award)\n",
    "                    \n",
    "                self.walker.move(choice(available_actions))\n",
    "                \n",
    "            self.walker.reset()\n",
    "    \n",
    "    def get_best_move(self):\n",
    "        cell_indx = self.states.index(self.walker.get_current_cell())\n",
    "        scores = self.qmatrix[cell_indx]\n",
    "        if scores.min() == scores.max():\n",
    "            return choice(self.walker.get_available_moves())\n",
    "        else:\n",
    "            best_score_indx = np.argmax(scores, axis=0)\n",
    "            return self.walker.get_all_moves()[best_score_indx]\n",
    "\n",
    "w = Walker(m)\n",
    "ql = QLearning(w, m.get_all_passages(), w.get_all_moves(), episode=10)\n",
    "ql.train()\n",
    "\n",
    "while not w.is_end():\n",
    "    action = ql.get_best_move()\n",
    "    w.move(action)\n",
    "    m.draw()\n",
    "    sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 1000 mazes for Deep QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bin.maze import Maze\n",
    "import pickle as pkl\n",
    "\n",
    "maze_set = []\n",
    "for _ in range(1000):\n",
    "    m = Maze(size=(29, 29))\n",
    "    m.generate()\n",
    "    maze_set.append(m)\n",
    "\n",
    "with open(\"data/maze-set.pkl\", 'wb') as f:\n",
    "    pkl.dump(maze_set, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
